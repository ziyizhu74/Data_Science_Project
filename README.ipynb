{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Please use published Databricks links below for better visuals.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) SF Crime Analysis Using Spark SQL and PySpark DataFrame\n",
    "\n",
    "[San Francisco Crime Analysis with Apache Spark for Big Data Processing](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2266522961450861/3112813335632301/421022585219207/latest.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Provided residents in SF and tourists with travel safety tips and business insights based on modeling and analysis of 10 most common crimes, top-3 dangerous neighbourhoods, and resolved/unresolved rates for different categories of crimes. Produced predictive models for future crime events by performing two time series analyses.\n",
    "\n",
    "- Utilized Python Urllib Module to access a large-scale open source database from DataSF.org for San Francisco crime analysis. Gained an in-depth understanding of distributed systems, algorithms, and cloud infrastructure by solving big data issues via PySpark dataframe, Spark SQL, and SQL in Databricks.\n",
    "\n",
    "- Built Python user-defined functions (UDF) to filter geographical data located at a certain distance from the city’s Financial District, specified by a spatial range as ‘downtown San Francisco’.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Recommender System\n",
    "\n",
    "[Movie Recommendations with Spark Collaborative Filtering](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2266522961450861/2354609215160139/421022585219207/latest.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Created a hybrid recommender system using both memory-based and model-based collaborative filtering computed by cosine-similarity and matrix factorization. Trained an Alternating Least Square (ALS) model with 5 latent factors and 5 regularization terms to predict the unknown ratings, respectively.\n",
    "\n",
    "- Optimized the ALS algorithm with Spark RDD-based MLlib API by measuring root-mean-square error of rating prediction.\n",
    "\n",
    "- Validated the performance of the ML model by manipulating rating data from MovieLens.org. Implemented the RMSE evaluation metric and output minimum error at 0.891.\n",
    "\n",
    "- Exposed the underlying patterns and relationships contained within the data through data visualizations using Python Matplotlib and Seaborn libraries. Plotted learning curves to detect overfitting for the Decision Tree Regression estimator,  suggested model complexity reduction techniques for a high variance scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) YouTube User Comments Semantic Analysis\n",
    "\n",
    "[YouTube Comments Sentiment Analysis and Natural Language Processing](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2266522961450861/1462984688696549/421022585219207/latest.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parsed and comprehended YouTube comments which classify users as either a cat/dog owner or not an owner. Trained supervised ML models including Logistic Regression, Decision Tree, Random Forests, and Gradient Boosting.\n",
    "\n",
    "- Preprocessed a 630MB dataset by data collection, cleaning, storage, and labeling. Conducted exploratory data analysis (EDA) to visualize the comment length distribution, dealt with imbalanced labels through resampling methods.\n",
    "\n",
    "- Architected a ML pipeline to transform categorical variables to numeric variables, vectorized feature columns using Word2Vec.\n",
    "\n",
    "- Designed four classifiers with the maximum AUC and identified the best model (GBT at 0.962). Evaluated model performance utilizing k-fold cross validation strategy, combined Python sklearn with matplotlib to plot ROC curves and Confusion Matrices. \n",
    "\n",
    "- Applied NLP techniques to identify top video creators, provided topic recommendations for the owners via PySpark and SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
